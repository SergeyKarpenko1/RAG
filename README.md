# В данном репозитории представлены два проекта, реализующие системы Retrieval-Augmented Generation (RAG), каждая из которых адаптирована под конкретные бизнес-задачи.
# Так же была произведена оценка метрик различных вариантов RAG при помощи фреймворка RAGAS.

## 1. RAG для компании Intelion

Intelion — компания, занимающаяся продажей майнингового оборудования. Данный RAG был разработан для того, чтобы сотрудники могли оперативно находить ответы на любые вопросы, касающиеся компании. База знаний включает информацию о департаментах, внутренних регламентах, правилах, философии и спектре услуг, предоставляемых компанией. Система реализована в формате чат-бота, что позволяет пользователям взаимодействовать с RAG в удобной форме.

Используемый стек технологий::

	•	Язык программирования: Python
	•	Фреймворки и библиотеки: Hugging Face, Transformers, OpenAI, FastAPI, LongChain, Chroma, RAGAS
	•	Модель эмбеддингов: OpenAIEmbeddings (модель: text-embedding-3-small/intfloat/multilingual-e5-base)
	•	LLM для генерации ответов: ChatOpenAI (модель: gpt-4o-mini)

Особенности:

	•	Реализованы различные варианты промптов для улучшения контекстуализации вопросов и помощи в переформулировании запросов.
	•	Внедрены техники ReAct Docstore для взаимодействия с пользователями.
	•	Проведены эксперименты с RAG-Fusion и RRF для улучшения качества генерации ответов.

## 2. RAG для заводских работников

Второй RAG предназначен для работников завода, целью которого является ускорение поиска информации в технической литературе. Основные источники знаний включают книги, такие как “Справочник конструктора-машиностроителя” (тома 1, 2, 3) и “Допуски и посадки”. Эти материалы были представлены в формате PDF, что добавило сложности в обработке, особенно из-за наличия большого количества таблиц.

Используемый дополнительный стек технологий::

	•	Библиотека для обработки PDF: pdfplumber

Особенности:

	•	Интегрирована сложная обработка PDF-файлов с таблицами для корректного извлечения данных.
	•	Реализован функционал, аналогичный RAG для Intelion, адаптированный для работы с технической литературой.

 ## Результаты работы

Ниже представлены результаты работы чат-бота, а также примеры того, как выглядели PDF файлы из технической литературы.

RAG для компании Intelion:
![image](https://github.com/user-attachments/assets/78c67e56-01ca-432c-a1cf-32fbe271019e)

RAG для заводских работников:
![image](https://github.com/user-attachments/assets/dddbf96c-9be8-46ca-80c8-2f72764a1442)

PDF файлы:

![image](https://github.com/user-attachments/assets/cea9c0bc-4309-4f15-84be-a8656fa47072)

## Анализ результатов производительности различныч RAG

Для этих целей нужно создать систему оценивания и протестировать то, что у нас получилось, в этом нам поможет библиотека RAGAs.

RAGAs — open source фреймворк, разработанный для оценки компонентов пайплайна без помощи человека. Он позволяет создать тестовый датасет и получить оценку построенного нами RAG’a.

При этом в тестовом датасете для создания вопросов по тексту используется GPT-3.5-turbo, а ответы на них генерируются GPT-4o-mini как самой совершенной моделью на текущее время. 

## Были взяты следующие комбинации RAG:

• basic_qa_vector_store: Простой векторный поиск

• basic_qa_result_bm25: К векторному поиску добавлен поиск по точным совпадениям слов(BM25) 

• basic_qa_result_reranked: Использует оба метода поиска (BM25 и векторный), с последующим переранжированием

• basic_qa_result_fusion_RRF: Генерирует несколько запросов и использует оба метода поиска, слияние результатов через RRF


| name                       | context_precision | faithfulness | answer_relevancy | context_recall | answer_correctness | answer_similarity |
|----------------------------|--------------------|--------------|------------------|----------------|--------------------|-------------------|
| basic_qa_vector_store      | 0.000              | 0.300        | 0.702250         | 0.00           | 0.405394           | 0.909810          |
| basic_qa_result_bm25       | 0.000              | 0.000        | 0.704887         | 0.00           | 0.418296           | 0.914565          |
| basic_qa_result_reranked   | 0.841              | 0.775        | 0.898564         | 0.75           | 0.487764           | 0.951729          |
| basic_qa_result_fusion_RRF | 0.000              | 0.350        | 0.797542         | 0.00           | 0.489093           | 0.948525          |

	1.	Precision Context (Точность контекста)
	•	basic_qa_result_reranked показывает значительно более высокий показатель точности контекста (0.841), чем остальные методы, у которых точность равна 0. Это говорит о том, что метод с переранжированием контекста лучше фокусируется на извлечении релевантных частей контекста.
	•	У basic_qa_vector_store, basic_qa_result_bm25, и basic_qa_result_fusion_RRF показатель равен нулю, что указывает на слабую способность этих методов к точному извлечению релевантного контекста.
 
	2.	Faithfulness (Верность)
	•	basic_qa_result_reranked показывает наивысший показатель верности (0.775), что означает, что переранжированный метод лучше сохраняет точность и релевантность предоставленного контекста для вопроса пользователя.
	•	basic_qa_result_fusion_RRF имеет верность 0.350, что все еще выше, чем у basic_qa_result_bm25 и basic_qa_vector_store (оба имеют 0.0), но значительно ниже, чем у переранжированного варианта. Это может означать, что RRF вносит дополнительные данные, но не всегда релевантные, что снижает качество финального ответа.
 
	3.	Answer Relevancy (Релевантность ответа)
	•	basic_qa_result_reranked снова показывает лучшие результаты с показателем 0.898, что указывает на то, что ответы на основе переранжированного контекста наиболее релевантны.
	•	basic_qa_result_fusion_RRF идет следом с показателем 0.798, что все еще является относительно высоким результатом, но уступает переранжированному методу.
	•	basic_qa_vector_store и basic_qa_result_bm25 имеют схожие результаты (около 0.70), что указывает на их ограниченные способности к предоставлению релевантных ответов.
 
	4.	Context Recall (Полнота контекста)
	•	basic_qa_result_reranked имеет показатель полноты 0.75, что говорит о способности метода находить релевантные части контекста, необходимые для ответа.
	•	Остальные методы показывают значение 0.0, что указывает на неспособность находить полный контекст для данных вопросов, что сказывается на качестве ответа.
 
	5.	Answer Correctness (Правильность ответа)
	•	Наивысший показатель правильности ответа у basic_qa_result_fusion_RRF (0.489), что немного лучше, чем у basic_qa_result_reranked (0.488).
	•	Несмотря на то, что basic_qa_result_reranked имеет лучшую релевантность и верность, RRF, возможно, находит дополнительные полезные аспекты контекста, что помогает немного улучшить правильность ответов.
 
	6.	Answer Similarity (Сходство ответа)
	•	Все модели имеют высокие показатели сходства ответа, что указывает на то, что, несмотря на различия в подходах, ответы достаточно схожи.
	•	basic_qa_result_reranked показывает наивысшее сходство (0.952), что еще раз подчеркивает его способность формулировать ответы, максимально близкие к ожидаемым.

 ## Вывод

Не всегда более сложные RAG работают лучше, поскольку увеличение сложности часто ведет к избыточности, снижению точности и увеличению “шума”.

Например, basic_qa_result_fusion_RRF, генерируя несколько запросов и комбинируя результаты через RRF, улучшает охват, но может добавлять дублирующиеся и нерелевантные данные, что снижает качество ответа.

В то же время, более простые методы, такие как basic_qa_result_reranked, эффективно используют оба подхода (BM25 и векторный поиск) с переранжированием, что позволяет достигать высокой точности и релевантности без избыточного усложнения.

Таким образом, баланс между простотой и охватом информации часто оказывается более важным, чем просто добавление дополнительных этапов слияния или множества запросов.






